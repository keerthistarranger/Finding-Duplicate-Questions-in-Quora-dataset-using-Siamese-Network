{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Duplicate_Quora_questions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpJ_YJp85z8T"
      },
      "source": [
        "import os\n",
        "import nltk\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.supervised import training\n",
        "from trax.fastmath import numpy as fastnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rnd\n",
        "\n",
        "# set random seeds\n",
        "#trax.supervised.trainer_lib.init_random_number_generators(34)\n",
        "rnd.seed(34)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygRBWqQJ_UW3",
        "outputId": "bcb8563e-2fa0-4ecb-dba5-7d5ba8aede51"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "-iQDYfz279w_",
        "outputId": "adb58c45-bbc2-47a2-cbd9-ab09ef64a13a"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-376a4ca4-1708-4417-b033-822bfc5d2ca2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-376a4ca4-1708-4417-b033-822bfc5d2ca2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving questions.csv to questions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5gRKrOH8Xnp"
      },
      "source": [
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['questions.csv']))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj2IMzOY5-83",
        "outputId": "c8d22675-3bda-4616-c6c1-ab646f3ec7d6"
      },
      "source": [
        "!pip install trax"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting trax\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/51/305b839f51d53abb393777f743e497d27bb341478f3fdec4d6ddaccc9fb5/trax-1.3.7-py2.py3-none-any.whl (521kB)\n",
            "\r\u001b[K     |▋                               | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 21.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 25.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40kB 26.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 51kB 25.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61kB 20.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 71kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 81kB 17.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 92kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 102kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 112kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 122kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 133kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 143kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 153kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 163kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 174kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 184kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 194kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 204kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 215kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 225kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 235kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 245kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 256kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 266kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 276kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 286kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 296kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 307kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 317kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 327kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 337kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 348kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 358kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 368kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 378kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 389kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 399kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 409kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 419kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 430kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 440kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 450kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 460kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 471kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 481kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 491kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 501kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 512kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 522kB 18.7MB/s \n",
            "\u001b[?25hCollecting funcsigs\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from trax) (5.4.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trax) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from trax) (1.15.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from trax) (0.4.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from trax) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trax) (1.19.5)\n",
            "Collecting t5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/83/376533337f39711929bb3f5c2263bfec4bf54abe5f2f1987f3ddf2e10a76/t5-0.9.0-py3-none-any.whl (230kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from trax) (0.2.11)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from trax) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from trax) (4.0.1)\n",
            "Collecting tensorflow-text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c0/c0fed4301f592c3b56638ae7292612c17d91a43891ba1aaf9636d535beae/tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from trax) (0.1.64+cuda110)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (1.3.0)\n",
            "Collecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/61f3f775514f2011f1b6a59e76392e2cfeb7a84b97812c3db34b47efa6dd/tfds_nightly-4.2.0.dev202104110106-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5->trax) (2.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5->trax) (1.8.1+cu101)\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5->trax) (1.1.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5->trax) (3.2.5)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/10/37df0bc87ebf84e1414613176340e3aadc3697d2bd112bf63d3d4b1e848a/mesh_tensorflow-0.1.19-py3-none-any.whl (366kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 54.0MB/s \n",
            "\u001b[?25hCollecting transformers>=2.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5->trax) (0.22.2.post1)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->trax) (3.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (1.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (5.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (3.12.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (4.41.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.23.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.29.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (20.3.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax) (0.11.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax) (2.4.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib->trax) (1.12)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5->trax) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5->trax) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->t5->trax) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax) (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->t5->trax) (1.0.1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->trax) (3.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->trax) (54.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.53.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (2.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.1.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.32.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.7.0->t5->trax) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5->trax) (7.1.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.28.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.4.8)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=806ff3b83dea88d706bf1606d6569558092c4d3cd1a1931e858d2198cf5d6026\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: funcsigs, tfds-nightly, rouge-score, tensorflow-text, mesh-tensorflow, tokenizers, sacremoses, transformers, portalocker, sacrebleu, sentencepiece, t5, trax\n",
            "Successfully installed funcsigs-1.0.2 mesh-tensorflow-0.1.19 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.5.1 sacremoses-0.0.44 sentencepiece-0.1.95 t5-0.9.0 tensorflow-text-2.4.3 tfds-nightly-4.2.0.dev202104110106 tokenizers-0.10.2 transformers-4.5.0 trax-1.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Jr_6cDUL9PyV",
        "outputId": "911fa7e4-0b19-4cdd-f238-b8b88996bc35"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8RsB0Dd9k2l"
      },
      "source": [
        "# Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWKMQi5p9qXz",
        "outputId": "a62c68b2-e7dc-41a4-fff7-cb8362e97749"
      },
      "source": [
        "N_train = 300000\n",
        "N_test  = 10*1024\n",
        "data_train = data[:N_train]\n",
        "data_test  = data[N_train:N_train+N_test]\n",
        "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
        "del(data) # remove to free memoryb"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: 300000 Test set: 10240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mDR3YDP9-f7"
      },
      "source": [
        "### Selecting only the questions that have duplicates to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yucqz2nm-QtW",
        "outputId": "156ca228-3014-4afa-be84-51d4e884b3cf"
      },
      "source": [
        "td_index = (data_train['is_duplicate'] == 1).to_numpy()\n",
        "td_index = [i for i, x in enumerate(td_index) if x] \n",
        "print('number of duplicate questions: ', len(td_index))\n",
        "print('indexes of first ten duplicate questions:', td_index[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of duplicate questions:  111486\n",
            "indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYMDdmA3-ace",
        "outputId": "408ad2f2-dddd-45f2-ffcf-ede5dca454b2"
      },
      "source": [
        "print(data_train['question1'][5])  #  Example of question duplicates (first one in data)\n",
        "print(data_train['question2'][5])\n",
        "print('is_duplicate: ', data_train['is_duplicate'][5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
            "is_duplicate:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obfNWc_j-fkK"
      },
      "source": [
        "Q1_train_words = np.array(data_train['question1'][td_index])\n",
        "Q2_train_words = np.array(data_train['question2'][td_index])\n",
        "\n",
        "Q1_test_words = np.array(data_test['question1'])\n",
        "Q2_test_words = np.array(data_test['question2'])\n",
        "y_test  = np.array(data_test['is_duplicate'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUWDGOty-6DL"
      },
      "source": [
        "###Tokenising the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pe7p-nq--7z"
      },
      "source": [
        "#create arrays\n",
        "Q1_train = np.empty_like(Q1_train_words)\n",
        "Q2_train = np.empty_like(Q2_train_words)\n",
        "\n",
        "Q1_test = np.empty_like(Q1_test_words)\n",
        "Q2_test = np.empty_like(Q2_test_words)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTQP8tNQ_DYu",
        "outputId": "85ac1e4d-1d25-43a7-e475-ebd4fa07d6ff"
      },
      "source": [
        "# Building the vocabulary with the train set         \n",
        "from collections import defaultdict\n",
        "\n",
        "vocab = defaultdict(lambda: 0)\n",
        "vocab['<PAD>'] = 1\n",
        "\n",
        "for idx in range(len(Q1_train_words)):\n",
        "    Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])\n",
        "    Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\n",
        "    q = Q1_train[idx] + Q2_train[idx]\n",
        "    for word in q:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab) + 1\n",
        "print('The length of the vocabulary is: ', len(vocab))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the vocabulary is:  36342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVIvF6OI_zgR",
        "outputId": "eaa8ee89-5967-4583-f33d-429ecf92d5c3"
      },
      "source": [
        "print(vocab['<PAD>'])\n",
        "print(vocab['Astrology'])\n",
        "print(vocab['Astronomy'])  #not in vocabulary, returns 0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzXCOlB6_4wy"
      },
      "source": [
        "for idx in range(len(Q1_test_words)): \n",
        "    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n",
        "    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0A-vddx___y",
        "outputId": "fa7877d5-45d4-4aef-88ee-3d8a80feb9be"
      },
      "source": [
        "print('Train set has reduced to: ', len(Q1_train) ) \n",
        "print('Test set length: ', len(Q1_test) ) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set has reduced to:  111486\n",
            "Test set length:  10240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhvk8ut5ALVH"
      },
      "source": [
        "## Converting a question to a tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMBK50aGAPYB"
      },
      "source": [
        "# Converting questions to array of integers\n",
        "for i in range(len(Q1_train)):\n",
        "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\n",
        "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\n",
        "\n",
        "        \n",
        "for i in range(len(Q1_test)):\n",
        "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n",
        "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U97oOEVbAVKR",
        "outputId": "ae431b6a-8c40-437c-a428-c5162129227a"
      },
      "source": [
        "print('first question in the train set:\\n')\n",
        "print(Q1_train_words[0], '\\n') \n",
        "print('encoded version:')\n",
        "print(Q1_train[0],'\\n')\n",
        "\n",
        "print('first question in the test set:\\n')\n",
        "print(Q1_test_words[0], '\\n')\n",
        "print('encoded version:')\n",
        "print(Q1_test[0]) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first question in the train set:\n",
            "\n",
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
            "\n",
            "encoded version:\n",
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] \n",
            "\n",
            "first question in the test set:\n",
            "\n",
            "How do I prepare for interviews for cse? \n",
            "\n",
            "encoded version:\n",
            "[32, 38, 4, 107, 65, 1015, 65, 11522, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGaoiB0RAYqB",
        "outputId": "662c94d4-2594-45eb-eb09-2b2d5cd78442"
      },
      "source": [
        "# Splitting the data\n",
        "cut_off = int(len(Q1_train)*.8)\n",
        "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
        "val_Q1, val_Q2 = Q1_train[cut_off: ], Q2_train[cut_off:]\n",
        "print('Number of duplicate questions: ', len(Q1_train))\n",
        "print(\"The length of the training set is:  \", len(train_Q1))\n",
        "print(\"The length of the validation set is: \", len(val_Q1))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of duplicate questions:  111486\n",
            "The length of the training set is:   89188\n",
            "The length of the validation set is:  22298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fxBN9lqAtYv"
      },
      "source": [
        "## Coding the data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpktOzcBAynL"
      },
      "source": [
        "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
        "    \"\"\"Generator function that yields batches of data\n",
        "\n",
        "    Args:\n",
        "        Q1 (list): List of transformed (to tensor) questions.\n",
        "        Q2 (list): List of transformed (to tensor) questions.\n",
        "        batch_size (int): Number of elements per batch.\n",
        "        pad (int, optional): Pad character from the vocab. Defaults to 1.\n",
        "        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n",
        "    Yields:\n",
        "        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n",
        "        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n",
        "              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n",
        "    \"\"\"\n",
        "\n",
        "    input1 = []\n",
        "    input2 = []\n",
        "    idx = 0\n",
        "    len_q = len(Q1)\n",
        "    question_indexes = [*range(len_q)]\n",
        "    \n",
        "    if shuffle:\n",
        "        rnd.shuffle(question_indexes)\n",
        "\n",
        "    while True:\n",
        "        if idx >= len_q:\n",
        "            idx = 0\n",
        "            if shuffle:\n",
        "                rnd.shuffle(question_indexes)\n",
        "        \n",
        "        q1 = Q1[question_indexes[idx]]\n",
        "        q2 = Q2[question_indexes[idx]]\n",
        "        \n",
        "        idx += 1\n",
        "        input1.append(q1)\n",
        "        input2.append(q2)\n",
        "        if len(input1) == batch_size:\n",
        "            max1=max([len(i) for i in input1])\n",
        "            max2=max([len(i) for i in input2])\n",
        "            max_len = max(max1,max2)\n",
        "            max_len = 2**int(np.ceil(np.log2(max_len)))\n",
        "            b1 = []\n",
        "            b2 = []\n",
        "            for q1, q2 in zip(input1, input2):\n",
        "                q1 = q1+[pad]*(max_len-len(q1))\n",
        "                q2 = q2+[pad]*(max_len-len(q2))\n",
        "                b1.append(q1)\n",
        "                b2.append(q2)\n",
        "            yield np.array(b1), np.array(b2)\n",
        "            # reset the batches\n",
        "            input1, input2 = [], []  "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGxM6vQrBT9U",
        "outputId": "5b78b3f0-f5d6-4d5a-f45f-b328ec41111b"
      },
      "source": [
        "# Testing\n",
        "batch_size = 2\n",
        "res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))\n",
        "print(\"First questions  : \",'\\n', res1, '\\n')\n",
        "print(\"Second questions : \",'\\n', res2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First questions  :  \n",
            " [[  30   87   78  134 2131 1980   28   78  594   21    1    1    1    1\n",
            "     1    1]\n",
            " [  30   55   78 3540 1460   28   56  253   21    1    1    1    1    1\n",
            "     1    1]] \n",
            "\n",
            "Second questions :  \n",
            " [[  30  156   78  134 2131 9516   21    1    1    1    1    1    1    1\n",
            "     1    1]\n",
            " [  30  156   78 3540 1460  131   56  253   21    1    1    1    1    1\n",
            "     1    1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw9RgG7wBlrH"
      },
      "source": [
        "# Defining the Siamese model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tONLzQBjBphX"
      },
      "source": [
        "\n",
        "def Siamese(vocab_size=len(vocab), d_model=128, mode='train'):\n",
        "    \"\"\"Returns a Siamese model.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).\n",
        "        d_model (int, optional): Depth of the model. Defaults to 128.\n",
        "        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.\n",
        "\n",
        "    Returns:\n",
        "        trax.layers.combinators.Parallel: A Siamese model. \n",
        "    \"\"\"\n",
        "\n",
        "    def normalize(x):  # normalizes the vectors to have L2 norm 1\n",
        "        return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims=True))\n",
        "    \n",
        "    q_processor = tl.Serial(  # Processor will run on Q1 and Q2.\n",
        "        tl.Embedding(vocab_size, d_model), # Embedding layer\n",
        "        tl.LSTM(d_model), # LSTM layer\n",
        "        tl.Mean(axis=1), # Mean over columns\n",
        "        tl.Fn('Normalize', lambda x: normalize(x))  # Apply normalize function\n",
        "    )  # Returns one vector of shape [batch_size, d_model].\n",
        "    \n",
        "    # Run on Q1 and Q2 in parallel.\n",
        "    model = tl.Parallel(q_processor, q_processor)\n",
        "    return model\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFNxRx8XB6UZ",
        "outputId": "c0bf7454-f282-4d14-e1ff-46b8e7e47e88"
      },
      "source": [
        "# check the model\n",
        "model = Siamese()\n",
        "print(model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parallel_in2_out2[\n",
            "  Serial[\n",
            "    Embedding_41790_128\n",
            "    LSTM_128\n",
            "    Mean\n",
            "    Normalize\n",
            "  ]\n",
            "  Serial[\n",
            "    Embedding_41790_128\n",
            "    LSTM_128\n",
            "    Mean\n",
            "    Normalize\n",
            "  ]\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OivAOt0rCLHp"
      },
      "source": [
        "## Implementing TripletLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IxNagxUCOLg"
      },
      "source": [
        "\n",
        "def TripletLossFn(v1, v2, margin=0.25):\n",
        "    \"\"\"Custom Loss function.\n",
        "\n",
        "    Args:\n",
        "        v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.\n",
        "        v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.\n",
        "        margin (float, optional): Desired margin. Defaults to 0.25.\n",
        "\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: Triplet Loss.\n",
        "    \"\"\"\n",
        "    \n",
        "    scores = fastnp.dot(v1,v2.T)  # pairwise cosine sim\n",
        "    batch_size = len(scores)\n",
        "    positive = fastnp.diagonal(scores)  # the positive ones (duplicates)\n",
        "    negative_without_positive = scores-2*fastnp.eye(batch_size)\n",
        "    closest_negative = fastnp.max(negative_without_positive,axis=1)\n",
        "    negative_zero_on_duplicate = (1-fastnp.eye(batch_size))*scores \n",
        "    mean_negative = fastnp.sum(negative_zero_on_duplicate,axis=1)/(batch_size - 1)\n",
        "    triplet_loss1 = fastnp.maximum(margin-positive+closest_negative,0.0)\n",
        "    triplet_loss2 = fastnp.maximum(margin-positive+mean_negative,0.0)\n",
        "    triplet_loss = fastnp.mean(triplet_loss1+triplet_loss2)\n",
        "    \n",
        "    \n",
        "    return triplet_loss"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMubKOJtCn3T",
        "outputId": "45ad4ec3-d5b6-4b3a-eea4-f90b58d8f131"
      },
      "source": [
        "v1 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
        "v2 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n",
        "TripletLossFn(v2,v1)\n",
        "print(\"Triplet Loss:\", TripletLossFn(v2,v1))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Triplet Loss: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udpUBxicCt7k"
      },
      "source": [
        "#TripletLoss layer function\n",
        "from functools import partial\n",
        "def TripletLoss(margin=0.25):\n",
        "    triplet_loss_fn = partial(TripletLossFn, margin=margin)\n",
        "    return tl.Fn('TripletLoss', triplet_loss_fn)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKeVxxrkC8HD"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52fPQE34C-Af",
        "outputId": "d0f07f3a-ce35-42f6-aaf8-7a40177d55a7"
      },
      "source": [
        "batch_size = 256\n",
        "train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'])\n",
        "val_generator = data_generator(val_Q1, val_Q2, batch_size, vocab['<PAD>'])\n",
        "print('train_Q1.shape ', train_Q1.shape)\n",
        "print('val_Q1.shape   ', val_Q1.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_Q1.shape  (89188,)\n",
            "val_Q1.shape    (22298,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jn8RiWuDCs3"
      },
      "source": [
        "lr_schedule = trax.lr.warmup_and_rsqrt_decay(400, 0.01)\n",
        "\n",
        "def train_model(Siamese, TripletLoss, lr_schedule, train_generator=train_generator, val_generator=val_generator, output_dir='model/'):\n",
        "    \"\"\"Training the Siamese Model\n",
        "\n",
        "    Args:\n",
        "        Siamese (function): Function that returns the Siamese model.\n",
        "        TripletLoss (function): Function that defines the TripletLoss loss function.\n",
        "        lr_schedule (function): Trax multifactor schedule function.\n",
        "        train_generator (generator, optional): Training generator. Defaults to train_generator.\n",
        "        val_generator (generator, optional): Validation generator. Defaults to val_generator.\n",
        "        output_dir (str, optional): Path to save model to. Defaults to 'model/'.\n",
        "\n",
        "    Returns:\n",
        "        trax.supervised.training.Loop: Training loop for the model.\n",
        "    \"\"\"\n",
        "    output_dir = os.path.expanduser(output_dir)\n",
        "\n",
        "    train_task = training.TrainTask(\n",
        "        labeled_data=train_generator,      \n",
        "        loss_layer=TripletLoss(margin=0.25),        \n",
        "        optimizer=trax.optimizers.Adam(0.01),         \n",
        "        lr_schedule=lr_schedule,\n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask(\n",
        "        labeled_data=val_generator,       \n",
        "        metrics=[TripletLoss(margin=0.25)],         \n",
        "    )\n",
        "    \n",
        "    model=Siamese()\n",
        "    training_loop = training.Loop(model,\n",
        "                                  train_task,\n",
        "                                  eval_tasks=[eval_task],\n",
        "                                  output_dir=output_dir\n",
        "                                )\n",
        "\n",
        "    return training_loop"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_sZXLh5UgGy"
      },
      "source": [
        "    output_dir='model/'\n",
        "    output_dir = os.path.expanduser(output_dir)\n",
        "\n",
        "    train_task = training.TrainTask(\n",
        "        labeled_data=train_generator,      \n",
        "        loss_layer=TripletLoss(margin=0.25),        \n",
        "        optimizer=trax.optimizers.Adam(0.01),         \n",
        "        lr_schedule=lr_schedule,\n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask(\n",
        "        labeled_data=val_generator,       \n",
        "        metrics=[TripletLoss(margin=0.25)],         \n",
        "    )\n",
        "    \n",
        "    model=Siamese()\n",
        "    training_loop_1 = training.Loop(model,\n",
        "                                  train_task,\n",
        "                                  eval_tasks=[eval_task],\n",
        "                                  output_dir=output_dir\n",
        "                                )"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwdaoNnEDWmI",
        "outputId": "c84b2404-71ad-478c-970b-4c873ab132b8"
      },
      "source": [
        "train_steps = 2000\n",
        "training_loop_1.run(train_steps)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step   2200: Ran 100 train steps in 77.00 secs\n",
            "Step   2200: train TripletLoss |  0.07292020\n",
            "Step   2200: eval  TripletLoss |  0.08424378\n",
            "\n",
            "Step   2300: Ran 100 train steps in 70.22 secs\n",
            "Step   2300: train TripletLoss |  0.06902982\n",
            "Step   2300: eval  TripletLoss |  0.08772273\n",
            "\n",
            "Step   2400: Ran 100 train steps in 68.60 secs\n",
            "Step   2400: train TripletLoss |  0.06303178\n",
            "Step   2400: eval  TripletLoss |  0.07960682\n",
            "\n",
            "Step   2500: Ran 100 train steps in 69.21 secs\n",
            "Step   2500: train TripletLoss |  0.05488934\n",
            "Step   2500: eval  TripletLoss |  0.08751141\n",
            "\n",
            "Step   2600: Ran 100 train steps in 75.48 secs\n",
            "Step   2600: train TripletLoss |  0.05314236\n",
            "Step   2600: eval  TripletLoss |  0.06741546\n",
            "\n",
            "Step   2700: Ran 100 train steps in 68.79 secs\n",
            "Step   2700: train TripletLoss |  0.05243163\n",
            "Step   2700: eval  TripletLoss |  0.06943834\n",
            "\n",
            "Step   2800: Ran 100 train steps in 68.40 secs\n",
            "Step   2800: train TripletLoss |  0.04995637\n",
            "Step   2800: eval  TripletLoss |  0.07617082\n",
            "\n",
            "Step   2900: Ran 100 train steps in 69.80 secs\n",
            "Step   2900: train TripletLoss |  0.04621105\n",
            "Step   2900: eval  TripletLoss |  0.07970079\n",
            "\n",
            "Step   3000: Ran 100 train steps in 70.59 secs\n",
            "Step   3000: train TripletLoss |  0.04606096\n",
            "Step   3000: eval  TripletLoss |  0.08291370\n",
            "\n",
            "Step   3100: Ran 100 train steps in 70.95 secs\n",
            "Step   3100: train TripletLoss |  0.04588105\n",
            "Step   3100: eval  TripletLoss |  0.06570622\n",
            "\n",
            "Step   3200: Ran 100 train steps in 71.95 secs\n",
            "Step   3200: train TripletLoss |  0.04102376\n",
            "Step   3200: eval  TripletLoss |  0.06394395\n",
            "\n",
            "Step   3300: Ran 100 train steps in 67.40 secs\n",
            "Step   3300: train TripletLoss |  0.04192355\n",
            "Step   3300: eval  TripletLoss |  0.06986925\n",
            "\n",
            "Step   3400: Ran 100 train steps in 70.48 secs\n",
            "Step   3400: train TripletLoss |  0.04227920\n",
            "Step   3400: eval  TripletLoss |  0.07619691\n",
            "\n",
            "Step   3500: Ran 100 train steps in 70.73 secs\n",
            "Step   3500: train TripletLoss |  0.04037572\n",
            "Step   3500: eval  TripletLoss |  0.05715331\n",
            "\n",
            "Step   3600: Ran 100 train steps in 71.08 secs\n",
            "Step   3600: train TripletLoss |  0.03818144\n",
            "Step   3600: eval  TripletLoss |  0.06023005\n",
            "\n",
            "Step   3700: Ran 100 train steps in 67.16 secs\n",
            "Step   3700: train TripletLoss |  0.03902927\n",
            "Step   3700: eval  TripletLoss |  0.06261372\n",
            "\n",
            "Step   3800: Ran 100 train steps in 69.93 secs\n",
            "Step   3800: train TripletLoss |  0.03841889\n",
            "Step   3800: eval  TripletLoss |  0.07331616\n",
            "\n",
            "Step   3900: Ran 100 train steps in 70.60 secs\n",
            "Step   3900: train TripletLoss |  0.03605890\n",
            "Step   3900: eval  TripletLoss |  0.04208175\n",
            "\n",
            "Step   4000: Ran 100 train steps in 69.10 secs\n",
            "Step   4000: train TripletLoss |  0.03657300\n",
            "Step   4000: eval  TripletLoss |  0.06625878\n",
            "\n",
            "Step   4100: Ran 100 train steps in 69.23 secs\n",
            "Step   4100: train TripletLoss |  0.03691079\n",
            "Step   4100: eval  TripletLoss |  0.07423293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZMfI4mMO-E4"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr5IPCzJPDOw"
      },
      "source": [
        "\n",
        "def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n",
        "    \"\"\"Function to test the accuracy of the model.\n",
        "\n",
        "    Args:\n",
        "        test_Q1 (numpy.ndarray): Array of Q1 questions.\n",
        "        test_Q2 (numpy.ndarray): Array of Q2 questions.\n",
        "        y (numpy.ndarray): Array of actual target.\n",
        "        threshold (float): Desired threshold.\n",
        "        model (trax.layers.combinators.Parallel): The Siamese model.\n",
        "        vocab (collections.defaultdict): The vocabulary used.\n",
        "        data_generator (function): Data generator function. Defaults to data_generator.\n",
        "        batch_size (int, optional): Size of the batches. Defaults to 64.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model.\n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "    for i in range(0, len(test_Q1), batch_size):\n",
        "        q1, q2 = next(data_generator(test_Q1[i:i + batch_size], test_Q2[i:i + batch_size], batch_size, pad=vocab['<PAD>'], shuffle=False))\n",
        "        y_test = y[i:i + batch_size]\n",
        "        v1, v2 = model((q1,q2))\n",
        "\n",
        "        for j in range(batch_size):\n",
        "            d = fastnp.dot(v1[j],v2[j].T)\n",
        "            res = d>threshold\n",
        "            accuracy += 1 if y_test[j]==res else 0\n",
        "    accuracy = accuracy/len(test_Q1)\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWkX05TYPZVP",
        "outputId": "1284c1d8-720e-49c8-c95e-3724eac16f37"
      },
      "source": [
        "accuracy = classify(Q1_test,Q2_test, y_test, 0.7, model, vocab, batch_size = 512) \n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.74853515625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKD8Kn5qmcmu"
      },
      "source": [
        "## Testing with custom questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnIRxfarmf2l"
      },
      "source": [
        "\n",
        "def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):\n",
        "    \"\"\"Function for predicting if two questions are duplicates.\n",
        "\n",
        "    Args:\n",
        "        question1 (str): First question.\n",
        "        question2 (str): Second question.\n",
        "        threshold (float): Desired threshold.\n",
        "        model (trax.layers.combinators.Parallel): The Siamese model.\n",
        "        vocab (collections.defaultdict): The vocabulary used.\n",
        "        data_generator (function): Data generator function. Defaults to data_generator.\n",
        "        verbose (bool, optional): If the results should be printed out. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the questions are duplicates, False otherwise.\n",
        "    \"\"\"\n",
        "    q1 = nltk.word_tokenize(question1)  # tokenize\n",
        "    q2 = nltk.word_tokenize(question2)  # tokenize\n",
        "    Q1, Q2 = [], []\n",
        "    for word in q1:  # encode q1\n",
        "        Q1 += [vocab[word]]\n",
        "    for word in q2:  # encode q2\n",
        "        Q2 += [vocab[word]]\n",
        "        \n",
        "\n",
        "    Q1, Q2 = next(data_generator([Q1], [Q2], batch_size=1, pad=vocab['<PAD>'], shuffle=False))\n",
        "    v1, v2 = model((Q1,Q2))\n",
        "    d = np.dot(v1,v2.T)\n",
        "    res = (d>threshold)[0][0]\n",
        "    \n",
        "    \n",
        "    if(verbose):\n",
        "        print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\n",
        "        print(\"d   = \", d)\n",
        "        print(\"res = \", res)\n",
        "\n",
        "    return res"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noARNVovmwMV",
        "outputId": "cefb2a09-c535-49dd-821c-7dface651dcd"
      },
      "source": [
        "\n",
        "question1 = \"When will I see you?\"\n",
        "question2 = \"When can I see you again?\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose = True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1  =  [[585  76   4  46  53  21   1   1]] \n",
            "Q2  =  [[ 585   33    4   46   53 7287   21    1]]\n",
            "d   =  [[0.92493355]]\n",
            "res =  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}